\section{Related work}

\subsection{TMC support in compilers}

Tail-recursion modulo cons was well-known in the Lisp community as
early as the 1970s. For example the REMREC system~\citep*{risch-73}
automatically transforms recursive functions into loops, and
supports modulo-cons tail recursion. It also supports tail-recursion
modulo associative arithmetic operators, which is outside the scope
of our work, but supported by the GCC compiler for example. The TMC
fragment is precisely described (in prose) by \citet*{friedman-wise-75}.

In the Prolog community it is a common pattern to implement destination-passing style through unification variables; in particular ``difference lists'' are a common representation of lists with a final hole.
Unification variables are first-class values: in particular they can be passed as function arguments, providing expressive, first-class support for destination-passing style in the source language.
For example, we do not support optimizing tail contexts of the form \ocaml{List.append li _?}, only direct constructor applications; this can be expressed in Prolog as just the difference list \ocaml{(List.append li X, X)} for a fresh destination variable \ocaml{X}.
But this expressiveness comes at a performance cost, and there is no static checking that the data is fully initialized at the end of computation.

\citet*{tmc-scala-2013} implement Ozma, an experimental backend for
the Scala programming language that targets the Oz virtual machine.
Oz~\citep*{oz-1994,oz-1995} is a language that integrates features
from logic- and functional-programming style, and in particular offers
pervasive ``dataflow values'', a generalization of Prolog unification
variables. Ozma brings to Scala an idiom of Oz, where Prolog-style
difference lists are used to represent potentially-infinite streams
that model synchronous concurrent agents. These lists must be
processed in constant stack space, so Ozma introduces
a tail-modulo-cons transformation in Prolog fashion: all data
constructor arguments (and some explicitly-annotated
function arguments) are transformed into dataflow values. The
motivation is expressivity, not performance, and the Ozma backend is
not competitive with the Scala JVM backend. Besides the obvious
engineering-effort differences, the pervasive use of dataflow values
may incur high constant overhead, making this approach unsuitable to
bring TMC to performance-conscious Scala users.

Independently of our work, Koka has implemented TMC starting in August
2020\footnote{\url{https://github.com/koka-lang/koka/commit/f6a343d31f486ea5edd44798dca7bca52d7b450c}}~\citep*{tmc-koka-2023}.
An interesting problem they had to solve, which does not occur in \OCaml,
is how to support TMC in presence of non-linear continuations. Our
correctness argument for TMC relies on the fact that the destination
is uniquely owned, and written exactly once; this property may not
hold in programs that use multishot continuations (\ocaml|call/cc|,
\ocaml|let/cc|, \ocaml|delim/cc|) or multishot effect handlers. The standard Koka runtime uses its
reference-counting machinery to determine that a destination is not
uniquely-owned anymore, and stores extra metadata in
partially-initialized blocks to be able to copy them on-demand in this
case. Its JavaScript back-end instead reverts to a CPS transformation
when non-linear control flow is detected.

\subsection{Reasoning about destination-passing-style}

In general, if we think of non-tail recursive functions as having an ``evaluation context'' representing the continuation of the recursive call, then the techniques to turn classes of calls into tail-calls correspond to different reified representations of non-tail contexts, equipped with specific (efficient) implementations of context composition and hole-plugging.
TMC comes from representing data-construction contexts as the partial data itself, with hole-plugging by mutation.
Associative-operator transformations represent the context \ocaml|1 + (4 + _?)| as the number \ocaml|5| directly.
(Sometimes it suffices to keep around an abstraction of the context; see John Clements' work stack-based security.)

\citet*{minamide-98} gives a ``functional'' interface to destination-passing-style programs, by presenting a partial data-constructor composition \ocaml{Foo(x,Bar(_?))} as a use-once, linear-typed function \ocaml{linfun h -> Foo(x,Bar(h))}.
Those special linear functions remain implemented as partial data, but they expose a referentially-transparent interface to the programmer, restricted by a linear type discipline.
This is a beautiful way to represent destination-passing style, orthogonal to our work: users of Minamide's system would still have to write the transformed version by hand, and we could implement a transformation into destination-passing style expressed in his system.
\citet*{sobel-friedman-98}, inspired by Minamide's work, derive tree-traversal functions with a concrete representation of their continuations that implement pointer inversion to remain tail-recursive.
Mezzo~\citep*{mezzo-2016} supports a more general-purpose type system based on separation logic, which can directly express uniquely-owned partially-initialized data, and its transformation into immutable, duplicable results.
(See the \href{https://protz.github.io/mezzo/code_samples/list.mz.html}{List} module of the Mezzo standard library, and in particular \ocaml{cell}, \ocaml{freeze} and \ocaml{append} in destination-passing-style).

\subsection{Correctness proof for TMC}

\citet*{tmc-koka-2023} provide a pen-and-paper correctness argument for TMC, or in fact a family of approaches based on optimized representations of classes of non-tail contexts, in the style of program calculation.
The clarity of their exposition is remarkable.

The implementation they prove correct, which corresponds to the approach described in \citet*{minamide-98}, results in a slightly less efficient generation where recursive calls to \ocaml{map_dps} are passed \emph{both} the start of the list and the destination to be written at its end.
The start of the list remains constant over all recursive calls, so our DPS version does not propagate it.

We were inspired by the generality of their presentation and verified that our proof technique can also be applied to some other TMC variants, by extending our mechanized development with a correctness proof for an
accumulator-passing-style transformation.

Finally, our correctness results are more precise and slightly stronger: they work in a well-typed setting where programs do not fail, when use untyped terms and show preservation of failure; their proofs assume a deterministic, non-effectful language, we use a more general non-deterministic, effectful language; finally, they have a very simple definition of program equivalence (reducing to the exact same value) that works well for semi-formal reasoning, but is unsuitable to scale the argument to other programming languages, whereas we use a standard notion of behavioral refinement that can scale to less idealized settings.
%
We get this extra generality mostly as a direct result of our methodology (relational program logic backed by a simulation); but showing preservation of failure requires some care when handling arithmetic operators in the accumulator-passing-style variant.

\subsection{Relational reasoning in separation logic}

Defining a program logic to capture unary program properties is a typical usage of \Iris; relational properties are rarer. \citet*{tassarotti-2017} use (a linear variant of) \Iris to prove the correctness of a program transformation that implements communication channels using shared references. See the related work of ReLoC Reloaded~\citep*{reloc-2021}.
\Xfrancois{+ thèse de Friis Vindum.}
\Xfrancois{ReLoC a été utilisé surtout pour vérifier des algos concurrents.}

A relational program logic can be justified in \Iris by interpreting it as a unary relation on the target program, typically involving the \texttt{wp} predicate of the base language. This approach is inspired by CaReSL~\citep*{caresl-2013}. We follow a more direct, traditional approach of interpreting the program logic as a (binary) simulation relation (defined in the \Iris meta-logic) which is shown (adequacy) to imply a refinement between the program behaviors (denotations).

It is in fact surprisingly difficult to define simulations in \Iris, if we expect them to be adequate (to correspond to the usual notion of simulation outside the \Iris world). This is due to meta-theoretical difficulties around the ``later'' modality which led to the Transfinite \Iris variant~\citep*{transfinite-iris-2021}. We started by defining simulations in Transfinite \Iris, but later moved to the \Simuliris approach~\citep*{simuliris-2022}, where simulations are defined in standard \Iris without using the ``later'' modality, using coinduction instead (via its impredicative encoding).

As a minor technical point of comparison to \Simuliris, our definition of behaviors (denotations) includes non-termination, successfully evaluating to a value, but also failing with an error, and refinement preserves all three kind of behaviors. We do not model undefined behaviors.

We believe that our approach (relational program logics justified by a simulation) is showing promises for compiler verification. Verification of CompCert\Xgabriel{TODO citation} passes typically prove a forward simulation result, which is strengthened into a backward simulation thanks to a determinism assumption. We get the desired backward simulation directly, with compositional proofs.

\subsection{Protocols}

The function-call rule of \Simuliris only relates calls to the same function, so it is unsuitable for program transformations that also transform function definitions. We parameterize our program logic and notion of simulation on a \emph{protocol} $\iProt$, an arbitrary predicate transformer injected into the relation. This approach is reminiscent of the \emph{axiomatic semantics}~\citep*{axiomatic-semantics-2014} proposed to reason about foreign function calls. In the \Iris community, we were directly inspired by \emph{protocols} \citet*{protocols-2021}, and this approach was also reused recently, in a unary setting, by \citet*{melocoton-2023}. Our notion of protocol is slightly more general than in those two works, as it can relate arbitrary expressions in evaluation position (not just function calls), and ``return'' after an axiomatic transition with arbitrary expressions (not just values). We use this extra generality to reason about accumulator-passing-style transformation in presence of ill-typed programs -- see \cref{subsec:protocols}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
