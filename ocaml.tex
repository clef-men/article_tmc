\section{\OCaml Implementation}
\label{sec:implementation}

For reasons of space, we moved some of the content in this section to \cref{app:more-ocaml}:
\begin{itemize}
\item \cref{subsec:alternative-impls}
  discusses alternative language implementation techniques that do not require TMC.
\item \cref{subsec:PR-history} provides a summary of the history of our implementation (started in 2015, restarted in 2020, merged in 2021).
\item \cref{subsec:applicative-impl} exhibits an applicative functor structure that makes our implementation nicely compact and readable.
\end{itemize}

\subsection{Examples}

Many functions that consume and produce lists are
tail-recursive-modulo-cons, in the sense that all they have a TMC
decomposition where all recursive calls are in TMC position. Notable
functions include \ocaml{map}, as already discussed, but also for
example:

\begin{minipage}{0.47\linewidth}
\begin{Ocaml}
let[@tail_mod_cons] rec filter p =
  function
  | [] -> []
  | x :: xs ->
    if p x
    then x :: filter p xs
    else filter p xs
\end{Ocaml}
\end{minipage}
\hfill
\begin{minipage}{0.53\linewidth}
\begin{Ocaml}
let[@tail_mod_cons] rec merge cmp l1 l2 =
  match l1, l2 with
  | [], l | l, [] -> l
  | h1 :: t1, h2 :: t2 ->
      if cmp h1 h2 <= 0
      then h1 :: merge cmp t1 l2
      else h2 :: merge cmp l1 t2
\end{Ocaml}
\end{minipage}

TMC is not useful only for lists or other ``linear'' data types, with
at most one recursive occurrence of the datatype in each
constructor.

\paragraph{A non-example} Consider a \ocaml{map} function on binary
trees:
\begin{Ocaml}
let[@tail_mod_cons] rec map f = function
| Leaf v -> Leaf (f v)
| Node(t1, t2) -> Node(map f t1, (map[@tailcall]) f t2)
\end{Ocaml}
In this function, there are two recursive calls, but only one of them
can be optimized; we used the \ocaml{[@tailcall]} attribute to direct
our implementation to optimize the call to the right child, as we will
discuss later. This is a \emph{bad} example of TMC usage in most
cases, given that
\begin{itemize}
\item If the tree is arbitrary, there is no reason that it would be
  right-leaning rather than left-leaning. Making only the right-child
  calls tail-calls does not protect us from stack overflows.
\item If the tree is known to be balanced, then in practice the depth
  is probably very small in both directions, so the TMC transformation
  is not necessary to have a well-behaved function.
\end{itemize}

\paragraph{Interesting non-linear examples} There \emph{are} interesting
examples of TMC-transformation on functions operating on tree-like
data structures, when there are natural assumptions about which child
is likely to contain a deep subtree. The OCaml compiler itself
contains a number of them; consider for example the following function
from the \ocaml{Cmm} module, one of its lower-level program
representations:

\begin{Ocaml}
let[@tail_mod_cons] rec map_tail f = function
  | Clet(id, exp, body) ->
      Clet(id, exp, map_tail f body)
  | Cifthenelse(cond, ifso, ifnot) ->
      Cifthenelse(cond, map_tail f ifso, (map_tail[@tailcall]) f ifnot)
  | Csequence(e1, e2) ->
      Csequence(e1, map_tail f e2)
  | Cswitch(e, tbl, el) ->
      Cswitch(e, tbl, Array.map (map_tail f) el)
  [...]
\end{Ocaml}

This function is traversing the ``tail'' context of an arbitrary
program term -- a meta-example! The \ocaml{Cifthenelse} node acts as
our binary-node constructor, we do not know which side is likely to be
larger, so TMC is not so interesting. The recursive calls for
\ocaml{Cswitch} are not in TMC position. But on the other hand the
\ocaml{Clet}, \ocaml{Csequence} cases are very beneficial to have in
TMC: while they have several recursive subtrees, they are in practice
only deeply nested in the direction that is turned into a tailcall by
the transformation. The OCaml compiler does sometimes encounter
machine-generated programs with a unusually long sequence of either
constructions, and the TMC transformation may very well avoid a stack
overflow in this case.

Another example would be
\href{https://github.com/ocaml/ocaml/pull/9636}{\#9636}, a patch to
the OCaml compiler proposed in June 2020 by Mark Shinwell, to get
a partially-tail-recursive implementation of the ``Common
Subexpression Elimination'' (CSE) pass through a manual
contiation-passing-style transform. Xavier Leroy remarked that the
existing implementation in fact fits the TMC fragment. Not all
recursive calls become tail-calls (this would require a more powerful
transformation or a longer, less readable patch), but the behavior of
TMC on the unchanged code matches the tail-call-ness proposed in the
human-written patch.

\subsection{Specifying which calls are in TMC position} \label{subsec:specification}
To reason about the stack usage of their programs, users must understand which calls are in tail-modulo-cons position.
Informally, they are the calls placed under any composition of either tail-recursive or constructor contexts.

We can in fact give a simple formal description of this intuition, here for \DataLang in \cref{fig:contexts}.
A tail frame $\datalangTailFrame$ is a single term-former with holes in tail-position.
A constructor frame $\datalangConsFrame$ is a single constructor term-former (we omit deterministic blocks, which do not occur in the source).
A tail context $\datalangTailCtx$ is an arbitrary composition of tail-frame, and a TMC context $\datalangTMCCtx$ is an arbitrary composition of tail frames and constructor frames.

If a source function can be decomposed in a TMC context $\datalangTMCCtx$ with source expressions in its holes, some of which are calls to TMC-transformed functions, then our relation admits a DPS transformation where all those function calls are tail-calls, and this transformation is reachable in our OCaml implementation, possibly by adding some annotations.

Note in particular that we do not optimize calls to the same function we are defining, direct calls to arbitrary other functions can be transformed, if those functions have been annotated to be TMC-transformed.
This is analoguous to how most functional languages support arbitrary \emph{tail calls} and not just tail self-recursion.
We seamlessly support mutually recursive functions, DPS calls into locally-bound functions, etc.

\begin{figure}[tp]
    \begin{tabular}{lclcl}
            $\datalangTailFrame[]$
            & $\ni$ &
            $\datalangTailFrame$
            & $\Coloneqq$ &
            $\datalangLet {\datalangVar} {\datalangExpr} \datalangCtxHole \mid \datalangIf \datalangExpr \datalangCtxHole \datalangCtxHole$
\\
            $\datalangConsFrame[]$
            & $\ni$ &
            $\datalangConsFrame$
            & $\Coloneqq$ &
            $\datalangBlock \datalangTag \datalangExpr \datalangCtxHole
            \mid \datalangBlock \datalangTag \datalangCtxHole \datalangExpr$
\\
            $\datalangTMCFrame[]$
            & $\ni$ &
            $\datalangTMCFrame$
            & $\Coloneqq$ &
            $\datalangTailFrame
             \mid
             \datalangConsFrame$
\\
            $\datalangTailCtx[]$
            & $\ni$ &
            $\datalangTailCtx$
            & $\Coloneqq$ &
            $\datalangCtxHole
             \mid
             \datalangTailFrame
             \mid
             \datalangTailCtx{[\datalangTailCtx]}$
\\
            $\datalangTMCCtx[]$
            & $\ni$ &
            $\datalangTMCCtx$
            & $\Coloneqq$ &
            $\datalangCtxHole
             \mid
             \datalangTMCFrame
             \mid
             \datalangTMCCtx{[\datalangTMCCtx]}$
    \end{tabular}
    \caption{\DataLang contexts for optimizable calls}
    \label{fig:contexts}
\end{figure}

\subsection{Design choices}

\subsubsection{Resolving non-determinism}

The main question faced by an implementation is how to resolve the
inherent non-determinism. We identified fairly different kinds of
non-determinism.

\paragraph{Choices with an obviously better alternative.} Some choices have an obviously better alternative, because they allow to strictly improve more programs. For example, some implementations of TMC limit themselves to calls that are immediately inside a constructor: they would optimize the recursive call to \ocaml|f| in \ocaml|Cons(x, f y)| but not, for example, in \ocaml|Cons(x1, Cons(x2, f y))|, or in \ocaml|Cons (x, if p then f y else z)|.

In the terms of \cref{subsec:specification}, some implementations only allow to optimize calling contexts of the form $\datalangTailCtx{[\datalangConsFrame]}$ or $\datalangTailCtx{[\datalangConsCtx]}$. We support a more general situation $\datalangTMCCtx = (\datalangTailFrame | \datalangConsFrame)^{*}$.

\paragraph{Choices with a subtly better alternative.} In some cases it
is possible to put a bit more work in the choice heuristics, to
generate slightly better code, in terms of performance or
readability. For example, some natural way to simplify the
implementation would result in more subterms being transformed in
destination-passing-style, only to finally use the
\RefTirName{DPSBase} rule without any DPS function call. The generated
code is slightly less pleasant to read, and in our experience it can
be noticeably slower.

Code readability is important in our context of an on-demand program
transformation used by performance experts: those experts will often
read the intermediate representations produced by the compiler to
check that their performance assumptions hold.

\paragraph{Incomparable choices: force the user to decide} The
remaining choices are between incomparable alternatives, that could
each be better than the other depending on the specific program or
programmer intent. Consider again our binary tree example,
\ocaml|Node(map f left, map f right)|: we could make either the first
or the second argument a tail-call.

Our policy in such cases is to let the user decide, by providing
control over the transformation choices using \ocaml{[@tailcall]}
program annotations, and to force the user to decide by raising an
error in case of ambiguity:
\begin{Ocaml}
  | Cifthenelse(cond, ifso, ifnot) ->
      Cifthenelse(cond, map_tail f ifso, map_tail f ifnot)
      /[^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^]/
/[Error]/: "[@tail_mod_cons]": this constructor application may be TMC-transformed
       in several different ways. Please disambiguate by adding an explicit
       "[@tailcall]" attribute to the call that should be made tail-recursive,
       or a "[@tailcall false]" attribute on calls that should not be
       transformed.
\end{Ocaml}

This approach would be incompatible with a view of the TMC
transformation as an implicit optimization, applied whenever
possible -- in that case one would rather have the compiler make
arbitrary choices rather than fail. We rather view TMC as a tool for
expert users to better reason about program performance. It should be
predictable and flexible (let the user express
their intent). Failing on the lack of annotations is an acceptable way
to drive user interaction.

\subsubsection{First-order implementation} A notable limitation of the
OCaml implementation is that it is first-order and non-modular in
nature: only direct calls to known functions can be converted into DPS
style, and the availability of a DPS variant is not exposed through
module abstractions.

It would be possible to allow DPS calls through external modules or
higher-order function parameters, by annotating interfaces and
function arguments with a \ocaml{[@tail_mod_cons]} annotation, and
elaborating them into a pair of functions, the direct-style and the DPS
version.

\subsection{Constructor compression} \label{subsec:constructor-compression} The translation as we described it formally in \cref{subsec:transformation} generates unpleasant (and slower) code when many constructors are nested before the recursive call. For example, consider this strange function: element in a list:
\begin{Ocaml}
let rec dup = function [] -> [] | x :: xs -> x :: x :: dup xs
\end{Ocaml}

Such nested constructors are common in compiler codebases, for
example a desugaring pass that transforms a single term-former into
a composition of several simpler term-formers, and applies recursively to
its subterms.

Following the TMC transformation naively, the DPS version would two location and performs two writes, leading to more complex code with worse constant factors. We introduced ``constructor compression'', an optimization of the generated code that avoids creating intermediary destinations for nested constructors. Compare the naive translation of \ocaml|dup|, on the left, and our compressed translation on the right:

\begin{minipage}{0.5\linewidth}
\begin{Ocaml}
let rec dup_dps dst ofs = function
| [] -> dst.(ofs) <- []
| x :: xs ->
  let dst1 = x :: ? in
  dst.(ofs) <- dst1;
  let dst2 = x :: ? in
  dst1.(1) <- dst2;
  dup_dps dst2 1 xs
\end{Ocaml}
\end{minipage}
\hfill
\begin{minipage}{0.5\linewidth}
\begin{Ocaml}
let rec dup_dps dst ofs = function
| [] -> dst.(ofs) <- []
| x :: xs ->
  let dst2 = x :: ? in
  dst1.(1) <- x :: dst2;
  dup_dps dst2 1 xs
\end{Ocaml}
\end{minipage}

This is implemented by passing as an extra transformation parameter a stack of ``delayed'' constructor applications, that are in context and must be applied to the result of the subterm. When we encounter the final recursive call, we ``reify'' this stack: the last/innermost constructor in the stack becomes the new destination (\ocaml|dst1| in the example above), and the rest of the stack is applied to the new destination when we write to the old destination. There are two subtleties:
\begin{enumerate}
\item \ocaml|if p then e1 else e2| has two subterms which are transformed in DPS style, and naively passing the stack of delayed constructors to both subterms would duplicate code; instead of also reify the current stack when encountering such constructs.
\item This transformation may permute constructor applications after effectful subterms. If the constructor application contains effectful arguments, those must be \ocaml|let|-bound at their original position to avoid changing the evaluation order.
\end{enumerate}

\subsection{Implementation} \label{subsec:implementation} Implementing the TMC transform is not an obvious top-down or bottom-up traversal, because it relies on two informations flowing in opposite directions: the transformation is \emph{possible} for subterms that are in tail-or-constructor position relative to the root of the function (top-down information), and it is \emph{desirable} for subterms whose leaves contain calls to TMC-transformed functions (bottom-up information). A naive approach is to perform a recursive traversal that tracks the top-down context and, on each subterm, recursively traverses the whole subterm to check desirability; this has quadratic time complexity, which is best avoided in production compilers.

Instead of trying to transform each subterm in a single pass, our implementation computes for each subterm a ``choice'', a summary of all the bottom-up information relevant to choose how to transform it -- once we have the top-down information available. This includes (1) the direct-style transform of the subterm, (2) the DPS-style transform of the subterm, (3) metadata tracking whether the transformation is beneficial (if a TMC-function call was found in tail-modulo-cons position), the list of TMC calls it contains (for error diagnostics), and whether some were explicitly requested by the user (for disambiguation). Computing transformed terms is not compositional, computing choices is compositional. We compute a choice for the whole function body (in one pass), from which we can directly extract the direct-style and DPS-style transformations of the function.

\subsection{Evaluation: benchmarks}

We measured the performance of \ocaml|List.map (fun n -> n + 1)| to validate our claims that the TMC transformation preserves program performance, and let us replace complex hand-optimized tail-recursive implementations.

\begin{figure}[tp]
\def\svgscale{0.8}
\graphicspath{{plots/}}
\input{plots/plot.5.pdf_tex}
\caption{\ocaml|List.map| benchmark on OCaml 5.1}
\label{fig:bench5}
\end{figure}

\newcommand{\bench}[1]{\textbf{#1}}

The \ocaml{List.map} versions in the graph are the following. We measure the code size (in lines) of each version, as a reasonable approximation of its implementation complexity.
\begin{description}
\item[\bench{nontail}] (5 lines of code) The naive, non-tail-recursive implementation.
\item[\bench{tail}] (9 lines) The naive tail-recursive implementation,
  \ocaml{List.rev (List.rev_map f xs)}.
\item[\bench{base}] (78 lines) The implementation of Jane Street's
  \href{https://github.com/janestreet/base}{Base} library
  (version 0.14.0). It is heavily hand-optimized to compensate for the costs
  of being tail-recursive.
\item[\bench{containers}] (55 lines) Another standard-library extension by Simon
  Cruanes; it is the hand-optimized tail-recursive implementation we
  included in the Prologue.
\item[\bench{batteries}] (29 lines) The implementation of the community-maintained
  \href{https://github.com/ocaml-batteries-team/batteries-included/}{Batteries}
  library. It is actually written in destination-passing-style, using
  an unsafe encoding with \ocaml{Obj.magic} to unsafely cast a mutable
  record into a list cell. (The trick comes from the older Extlib
  library, was introduced by Brian Hurt in 2003, and has a comment crediting Jacques
  Garrigue for the particular encoding used.)
\item[\bench{tmc}] (5 lines) ``Our'' version, the last version of the Prologue: the
  result of applying our implementation of the TMC transformation to
  the simple, non-tail-recursive version.
\item[\bench{tmc-unrolled}] (18 lines) The result of manually unrolling the \bench{tmc} implementation three times, to be compare with \bench{base} and \bench{containers} that use manual unrolling as well.
\end{description}

The benchmarks reports the relative performance compared to the naive tail-recursive version as our baseline. They were run on OCaml 5.1 in July 2024, on a Linux machine with an AMD Ryzen processor fixed at a 3Ghz frequency, looping each measurement for 5s (a single \ocaml|List.map| run takes between 7ns, for empty lists, and 89ms on lists with a million element).

Qualitatively we see that there are four groups:
\begin{itemize}
\item \bench{tmc}, \bench{batteries} perform very on large lists, but they
  are slower than the baseline on small lists.
\item \bench{nontail} performs better than \bench{tmc}, \bench{batteries} on list sizes up to $10^4$, and much worse on larger lists.
\item \bench{base}, \bench{containers} perform noticeably better than \bench{nontail} at all sizes,
  but worse than the TMC versions above size $10^4$.
\item \bench{tmc-unrolled} is the best option, it performs as well as \bench{base} and \bench{containers} before $10^4$, and as well as \bench{tmc}, \bench{batteries} afterwards.
\end{itemize}
Our interpretation of the result is that some unrolling makes a noticeable performance difference for such a short function: \bench{tmc} is not good enough on smaller lists, but \bench{tmc-unrolled} is the best-performing, despite much simpler than the \bench{base} and \bench{containers} version.

\paragraph{Asymptotics of \bench{nontail}} The bad behavior of \bench{nontail} on large lists comes from a quadratic behavior on very large call stacks, coming from a repeated scan of the call stack during minor collections. (The OCaml compiler and runtime could be tweaked to avoid this quadratic behavior, at the cost of some small constant overhead on function returns.)

\paragraph{Memory usage} The \bench{tail} version allocates twice as many words as the \bench{tail} or TMC versions. The \bench{base} and \bench{containers} version allocate more as well, once they reach the cutoff where they move to their tail-recursive regime. This probably does not matter for most use-cases, and it does not show in the time measurements in the microbenchmark.

\subsection{Evaluation: adoption}

% [@tail_mod_cons] usage on Github

% Search URL:
%   https://github.com/search?q=tail_mod_cons+lang%3Aocaml&type=code

% Results (November 13th 2023):
%   - in the OCaml stdlib
%     + Melange
%       (reused from stdlib)
%     + janestreet/base
%       (with manual unfolding)
%   - in other general utility modules
%     https://github.com/RedPRL/asai/blob/ac523674579772e5929c8d912d407b8b7db89c74/src/Utils.ml#L33
%     https://github.com/jonathan-laurent/KaTie/blob/2db0d2cf223fae003b26bdf4c82a9788b5804bc7/src/utils.ml#L95
%     https://github.com/jamsidedown/ocaml-cll/blob/394effa65b5d3f883e2de8322ed60fb7aa495bec/examples/crab_cups.ml#L61
%   - in other user code
%     at list type:
%       https://github.com/brendanzab/language-garden/blob/9cc21e2f57228556cf0b867ca2874ceb4a4250ec/compile-arith/lib/StackLang.ml#L63
%       https://github.com/abella-prover/abella/blob/ceee13822001137898ca5de9c76a315da3d1f0e3/src/extensions.ml#L421
%       https://github.com/bikallem/spring/blob/6d10fef0b21caea3f975ff13132f5994e7c37db5/lib_spring/response.ml#L99
%       https://github.com/bikallem/spring/blob/6d10fef0b21caea3f975ff13132f5994e7c37db5/lib_spring/headers.ml#L150
%       https://github.com/polytypic/io/blob/dbe4d37a98ef958178fe18bb4dae396a5537392e/src/io/io.ml#L8
%       https://github.com/avsm/eeww/blob/5b6c0617306f4c9d8b44bf07ef4d45ec9668dd0c/lib/cohttp/cohttp-eio/src/rwer.ml#L43
%       https://github.com/just-max/less-power/blob/96f8e88f72275246b6bc175e44c732aa6e08ce7f/src/common/path_util.ml#L18
%       https://github.com/dalps/ocaml-challenge/blob/8fe115023457b6b4359ef736c78ba980cd871717/3/extract/solve.ml#L4
%       https://github.com/Octachron/ocaml-changelog-analyzer/blob/d6757b9576b5070ea3cfe6d4f4f79aaa3cc6e5d4/parse/release.ml#L4
%       https://github.com/Skyb0rg007/PL-Reading-Group/blob/7002ae35ba69fb9010e5049eee88ab475bc79ec3/list-optimizations/lib/adt.ml#L44
%       https://github.com/jfeser/symetric/blob/f49a57afc90a2c1e38f1097f98bd74725c074b9b/lib/tower.ml#L75
%       https://github.com/verse-lab/sisyphus/blob/a08addae06bbccb1e6ea68bac3d7f9eeea4197be/lib/dynamic/utils.ml#L65
%       https://github.com/jaymody/ocaml-tokenizers/blob/06cbce75d2865690cb39017222efff5c284bc721/lib/utils.ml#L18
%       https://github.com/Bannerets/ocaml-kdl/blob/687c404ebeceef7fd905935c23665294133f99e6/src/lens.ml#L83
%       https://github.com/OCADml/OCADml/blob/f5dfbf55f9c19ad808daa0df4d76a55e58756e5f/lib/poly3.ml#L33
%     other type
%       https://github.com/johnridesabike/acutis/blob/4113fb516d9c5dd6f2dbfd9657f52c5ae7a5dcae/lib/matching.ml#L161
%         (on-demand stream as a record of functions)
%       https://github.com/RedPRL/ocaml-bwd/blob/fbf496b29532085b38073eaa62ba3d22ac619d5d/src/BwdNoLabels.ml#L60
%         (snoc list)
%       https://github.com/Skyb0rg007/PL-Reading-Group/blob/7002ae35ba69fb9010e5049eee88ab475bc79ec3/effects/lib/free/tseq.ml#L44
%         (difference list gadt)

%   - Misuse
%     https://github.com/chengsun/simd-sexp/commit/e714a8205c6df512d920a31a4dd2448975703c55
%       (already tail-recursive)
%     https://github.com/gridbugs/llama/blob/96d1c96c31ff136f465b5f37c981fff591bac6fd/src/midi/byte_array_parser.ml#L50
%       (needless complexity)
%     https://github.com/LimitEpsilon/lambda-interpreter/blob/ab8e81de7f896aa64eba14e23d964b9705e94161/lib/evaluate.ml#L46
%       (already tail-recursive)

The TMC transformation was first made available to users in OCaml 4.14.0, released in March 2022.
At the time there were no users of the feature.
Notably, the OCaml standard library had intentionally not been modified to start using it: before the release, we did not want the stdlib codebase to depend on a not-available-yet feature, and after the release we decided not to push for adoption (we may be biased about the benefits/importance of TMC), and let other contributors propose its use, after doing their own evaluation of performance impact and code-clarity benefits.

Over time, \ocaml|[@tail_mod_cons]| was adopted in a few places in the OCaml standard library, either to make some functions tail-recursive that previously were not, or simplify some complex tail-recursive implementations. As of spring 2024, the feature is now used in \ocaml|Hashtbl.find_all| and in \ocaml|List| module (\ocaml|init, map, mapi, map2, find_all, filteri, filter_map, take, take_while, of_seq|). \ocaml|init| and the \ocaml|map*| functions, which are the most heavily used, were unrolled once -- the minimal amount observed to preserve the non-tailrec performance for small lists. Other functions are written in the simplest possible way. (All \texttt{stdlib} uses so far build lists rather than another datatype.)

We performed a systematic search for \ocaml|[@tail_mod_cons]| usage on November 2023, and we found that it was also used
\begin{itemize}
\item in a few utility modules (general-purpose functions designed to extend or replace the standard library), notably in Jane Street's \texttt{base} library.
\item in the middle of domain-specific user code, to build lists, in 14 different projects
\item in the middle of user code, to build other types than lists, in three projects:
  \begin{itemize}
  \item in \texttt{RedPRL}\footnote{\url{https://github.com/RedPRL/ocaml-bwd/blob/fbf496b29532085b38073eaa62ba3d22ac619d5d/src/BwdNoLabels.ml\#L60}},
    it is used to build snoc lists
  \item in a project named \texttt{PL-reading-group}\footnote{\url{https://github.com/Skyb0rg007/PL-Reading-Group/blob/7002ae35ba69fb9010e5049eee88ab475bc79ec3/effects/lib/free/tseq.ml\#L44}},
    it is used to build a GADT of difference lists
  \item in \texttt{acutis}\footnote{\url{https://github.com/johnridesabike/acutis/blob/4113fb516d9c5dd6f2dbfd9657f52c5ae7a5dcae/lib/matching.ml\#L161}},
    in a group of mutually-recursive functions that builds a complex AST structure used options and nested records
  \end{itemize}
\end{itemize}

We also found three cases where the annotation is (in our opinion) misused: in two cases, the function is already tail-recursive, so there is no need for the annotation, and in a third case\footnote{\url{https://github.com/gridbugs/llama/blob/96d1c96c31ff136f465b5f37c981fff591bac6fd/src/midi/byte_array_parser.ml\#L50}} we consider that the use is gratuitous and can be replaced by already-available standard library functions.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: