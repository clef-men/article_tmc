\section{\OCaml Implementation}
\label{sec:implementation}

For reasons of space, we moved some of the content in this section to \cref{app:more-ocaml}:
%
\cref{subsec:alternative-impls}
  discusses alternative language implementation techniques that do not require TMC.
%
\cref{subsec:PR-history} provides a summary of the history of our implementation (started in 2015, restarted in 2020, merged in 2021).
%
\cref{subsec:applicative-impl} exhibits an applicative functor structure that makes our implementation nicely compact and readable.
%
\cref{subsec:adoption} surveys the adoption of the TMC transformation in the standard library,
  and in third-party \OCaml code bases, that happened since the feature was released in 2022.

\subsection{Examples}
\label{subsec:ocaml-examples}

% Many functions that consume and produce lists are
% tail-recursive-modulo-cons, in the sense that they admit a TMC
% transformation where all recursive calls become tail calls. Notable
% functions include \ocaml{map}, as already discussed, but also for
% example:

\begin{minipage}{0.47\linewidth}
\begin{Ocaml}
let[@tail_mod_cons] rec filter p =
  function
  | [] -> []
  | x :: xs ->
    if p x
    then x :: filter p xs
    else filter p xs
\end{Ocaml}
\end{minipage}
\hfill
\begin{minipage}{0.53\linewidth}
\begin{Ocaml}
let[@tail_mod_cons] rec merge cmp l1 l2 =
  match l1, l2 with
  | [], l | l, [] -> l
  | h1 :: t1, h2 :: t2 ->
      if cmp h1 h2 <= 0
      then h1 :: merge cmp t1 l2
      else h2 :: merge cmp l1 t2
\end{Ocaml}
\end{minipage}

TMC is not useful only for lists or other ``linear'' data types, with
at most one recursive occurrence of the datatype in each
constructor. An example follows.

\paragraph{A non-example} Consider a \ocaml{map} function on binary
trees:
\begin{Ocaml}
let[@tail_mod_cons] rec map f = function
| Leaf v -> Leaf (f v)
| Node(t1, t2) -> Node(map f t1, (map[@tailcall]) f t2)
\end{Ocaml}
In this function, there are two recursive calls, but only one of them
can be optimized; we used the \ocaml{[@tailcall]} attribute to direct
our implementation to optimize the call to the right child, as we will
discuss later. This is a \emph{bad} example of TMC usage in most
cases, given that
\begin{itemize}
\item If the tree is arbitrary, there is no reason that it would be
  right-leaning rather than left-leaning. Making only the right-child
  calls tail-calls does not protect us from stack overflows.
\item If the tree is known to be balanced, then in practice the depth
  is probably very small in both directions, so the TMC transformation
  is not necessary to have a well-behaved function.
\end{itemize}

\paragraph{Interesting non-linear examples} There \emph{are} interesting
examples of TMC-transformation on functions operating on tree-like
data structures, when there are natural assumptions about which child
is likely to contain a deep subtree. The \OCaml compiler itself
contains a number of them; consider for example the following function
from the \ocaml{Cmm} module, one of its lower-level program
representations:

\begin{Ocaml}
let[@tail_mod_cons] rec map_tail f = function
  | Clet(id, exp, body) ->
      Clet(id, exp, map_tail f body)
  | Cifthenelse(cond, ifso, ifnot) ->
      Cifthenelse(cond, map_tail f ifso, (map_tail[@tailcall]) f ifnot)
  | Csequence(e1, e2) ->
      Csequence(e1, map_tail f e2)
  | Cswitch(e, tbl, el) ->
      Cswitch(e, tbl, Array.map (map_tail f) el)
  [...]
\end{Ocaml}

This function is traversing the ``tail'' context of an arbitrary program term -- a meta-example!
The \ocaml{Cifthenelse} node acts as our binary-node constructor.
We do not know which side is likely to be larger, so TMC is not so interesting.
The recursive calls for \ocaml{Cswitch} are not in TMC position.
But on the other hand the \ocaml{Clet}, \ocaml{Csequence} do benefit from the TMC transformation: while they have several recursive subtrees, they are in practice only deeply nested in the direction that is turned into a tailcall by the transformation.
The \OCaml compiler does sometimes encounter machine-generated programs with a unusually long sequence of either constructions, and the TMC transformation may very well avoid a stack overflow in this case.

Another example would be \href{https://github.com/ocaml/ocaml/pull/9636}{\#9636}, a patch to the \OCaml compiler proposed in June 2020 by Mark Shinwell, to get a partially-tail-recursive implementation of the ``Common Subexpression Elimination'' (CSE) pass through a manual continuation-passing-style transform.
Xavier Leroy remarked that the existing implementation in fact fits the TMC fragment. Not all recursive calls become tail-calls (this would require a more powerful transformation or a longer, less readable patch), but the behavior of TMC on the unchanged code matches the tail-call-ness proposed in the human-written patch.

\subsection{Specifying Which Calls are in TMC Position} \label{subsec:specification}
To reason about the stack usage of their programs, users must understand which calls are in tail-modulo-cons position.
Informally, they are the calls placed under any composition of either tail-recursive or constructor contexts.

We can in fact give a simple formal description of this intuition, here for \DataLang in \cref{fig:contexts}.
A tail frame $\datalangTailFrame$ is a single term-former with holes in tail-position.
A constructor frame $\datalangConsFrame$ is a single constructor term-former (we omit deterministic blocks, which do not occur in the source).
A tail context $\datalangTailCtx$ is an arbitrary composition of tail-frame, and a TMC context $\datalangTMCCtx$ is an arbitrary composition of tail frames and constructor frames.

If a source function can be decomposed in a TMC context $\datalangTMCCtx$ with source expressions in its holes, some of which are calls to TMC-transformed functions, then our relation admits a DPS transformation where all those function calls are tail-calls, and this transformation is reachable in our \OCaml implementation, possibly by adding some annotations.

Note in particular that we do not optimize calls to the same function we are defining, direct calls to arbitrary other functions can be transformed, if those functions have been annotated to be TMC-transformed.
This is analogous to how most functional languages support arbitrary \emph{tail calls} and not just tail self-recursion.
We seamlessly support mutually recursive functions, DPS calls into locally-bound functions, etc.

\begin{figure}[tp]
    \begin{tabular}{lclcl}
            $\datalangTailFrame[]$
            & $\ni$ &
            $\datalangTailFrame$
            & $\Coloneqq$ &
            $\datalangLet {\datalangVar} {\datalangExpr} \datalangCtxHole \mid \datalangIf \datalangExpr \datalangCtxHole \datalangCtxHole$
\\
            $\datalangConsFrame[]$
            & $\ni$ &
            $\datalangConsFrame$
            & $\Coloneqq$ &
            $\datalangBlock \datalangTag \datalangExpr \datalangCtxHole
            \mid \datalangBlock \datalangTag \datalangCtxHole \datalangExpr$
\\
            $\datalangTMCFrame[]$
            & $\ni$ &
            $\datalangTMCFrame$
            & $\Coloneqq$ &
            $\datalangTailFrame
             \mid
             \datalangConsFrame$
\\
            $\datalangTailCtx[]$
            & $\ni$ &
            $\datalangTailCtx$
            & $\Coloneqq$ &
            $\datalangCtxHole
             \mid
             \datalangTailFrame
             \mid
             \datalangTailCtx{[\datalangTailCtx]}$
\\
            $\datalangTMCCtx[]$
            & $\ni$ &
            $\datalangTMCCtx$
            & $\Coloneqq$ &
            $\datalangCtxHole
             \mid
             \datalangTMCFrame
             \mid
             \datalangTMCCtx{[\datalangTMCCtx]}$
    \end{tabular}
    \caption{\DataLang contexts for optimizable calls}
    \label{fig:contexts}
\end{figure}

\subsection{Design Choices}

\subsubsection{Opt-in Rather than Opt-out}\label{subsec:optin}
We made our transformation \emph{opt-in}, the user has to explicit use
the \ocaml{[@tail_mod_cons]}, rather than \emph{opt-out}, where the
compiler would automatically detect program in the TMC fragment to
transform them. There are at least three reasons for this choice, in
increasing order of importance. First, the transformation duplicates
code, as it generates a direct- and a destination-passing-style
version of the function; in particular we could suffer from
a code-size blow-up on nested transformable functions. Second, the
transformation may change the evaluation order of function arguments,
in a way that conforms to the OCaml specification but may break
programs in practice (bad!), so we would have to restrict it to only
transform calls with syntactically-pure arguments. Third and most
importantly, our implementation may have bugs, which may silently
introduce miscompilations in user code. There are millions of lines of
OCaml code out there, and we have no idea which portion would be
transformed. Doing this implicitly would risk running into
compile-time, runtime or correctness issues that we have not foreseen,
it would have been much harder to convince OCaml maintainers to
include this feature if it was opt-out.

\subsubsection{Resolving Non-determinism}

The main question faced by an implementation is how to resolve the
inherent non-determinism in the rewrite relation -- how to decide
between several possible results of the transformation. We identified
fairly different kinds of non-determinism.

\paragraph{Choices with an obviously better alternative.}
Some choices offer an alternative that is obviously better than the others, because it allows to strictly improve more programs. For example, some implementations of TMC limit themselves to calls that are immediately inside a constructor: they would optimize the recursive call to \ocaml|f| in \ocaml|Cons(x, f y)| but not, for example, in \ocaml|Cons(x1, Cons(x2, f y))|, or in \ocaml|Cons (x, if p then f y else z)|.

In the terms of \cref{subsec:specification}, those implementations only allow to optimize calling contexts of the form $\datalangTailCtx{[\datalangConsFrame]}$ or $\datalangTailCtx{[\datalangConsCtx]}$. Our implementation supports the more general situation $\datalangTMCCtx = (\datalangTailFrame | \datalangConsFrame)^{*}$. Both approaches are included in our non-deterministic relation -- we prove them both correct -- but optimizing more calls is obviously better.

\paragraph{Choices with a subtly better alternative.} In some cases it
is possible to put a bit more work in the choice heuristics, to
generate slightly better code, in terms of performance or
readability. For example, some natural way to simplify the
implementation would result in more subterms being transformed in
destination-passing-style, only to finally use the
\RefTirName{DPSBase} rule without any DPS function call. The generated
code is slightly less pleasant to read, and in our experience it can
be noticeably slower. (We detail such a situation in \cref{subsec:constructor-compression}.)

Code readability is important in our context of an on-demand program
transformation used by performance experts: those experts will often
read the intermediate representations produced by the compiler to
check that their performance assumptions hold.

\paragraph{Incomparable choices: force the user to decide} \label{subsec:user-control}
The remaining choices are between incomparable alternatives, that could
each be better than the other depending on the specific program or
programmer intent. Consider again our binary tree example,
\ocaml|Node(map f left, map f right)|: we could make either the first
or the second argument a tail-call.

Our policy in such cases is to let the user decide, by providing
control over the transformation choices using \ocaml{[@tailcall]}
program annotations, and to force the user to decide by raising an
error in case of ambiguity:
\begin{Ocaml}
  | Cifthenelse(cond, ifso, ifnot) ->
      Cifthenelse(cond, map_tail f ifso, map_tail f ifnot)
      /[^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^]/
/[Error]/: "[@tail_mod_cons]": this constructor application may be TMC-transformed
       in several different ways. Please disambiguate by adding an explicit
       "[@tailcall]" attribute to the call that should be made tail-recursive,
       or a "[@tailcall false]" attribute on calls that should not be
       transformed.
\end{Ocaml}

This approach is incompatible with a view of the TMC
transformation as an implicit optimization, applied whenever
possible -- in that case one would rather have the compiler make
arbitrary choices rather than fail. We rather view TMC as a tool for
expert users to better reason about program performance. It should be
predictable and flexible (let the user express
their intent). Failing due to the lack of annotations is an acceptable way
to drive user interaction.

\subsubsection{First-order Implementation}\label{subsubsec:first-order}
A notable limitation of the \OCaml implementation is that it is first-order and non-modular in nature: only direct calls to known functions can be converted into DPS style, and the availability of a DPS variant is not exposed through module abstractions.
It would be possible to allow DPS calls through external modules or higher-order function parameters, by annotating interfaces and function arguments with a \ocaml{[@tail_mod_cons]} annotation, and elaborating them into a pair of functions, the direct-style and the DPS version.

\subsection{Constructor Compression} \label{subsec:constructor-compression} The translation as we described it formally in \cref{subsec:transformation} generates unpleasant code when many constructors are nested before the recursive call. For example, consider this strange function duplicating each element of a list:
\begin{Ocaml}
let rec dup = function [] -> [] | x :: xs -> x :: x :: dup xs
\end{Ocaml}

Such nested constructors are common in compiler code bases, for
example a desugaring pass that transforms a single term-former into
a composition of several simpler term-formers, and applies recursively to
its subterms.

Following the TMC transformation naively, the DPS version would propagate two different locations and performs two writes. We introduced ``constructor compression'', an optimization of the generated code that avoids creating intermediary destinations for nested constructors, leading to clearer generated code and better constant factors. Compare the naive translation of \ocaml|dup|, on the left, and our compressed translation on the right:

\begin{minipage}{0.5\linewidth}
\begin{Ocaml}
let rec dup_dps dst ofs = function
| [] -> dst.(ofs) <- []
| x :: xs ->
  let dst1 = x :: ? in
  dst.(ofs) <- dst1;
  let dst2 = x :: ? in
  dst1.(1) <- dst2;
  dup_dps dst2 1 xs
\end{Ocaml}
\end{minipage}
\hfill
\begin{minipage}{0.5\linewidth}
\begin{Ocaml}
let rec dup_dps dst ofs = function
| [] -> dst.(ofs) <- []
| x :: xs ->
  let dst2 = x :: ? in
  dst.(ofs) <- x :: dst2;
  dup_dps dst2 1 xs
\end{Ocaml}
\end{minipage}

This is implemented by passing a new transformation parameter: a stack of ``delayed'' constructor applications, that are in context and must be applied to the result of the subterm. When we encounter the final recursive call, we ``reify'' this stack: the last/innermost constructor in the stack becomes the new destination (\ocaml|dst2| in the example above), and the rest of the stack is applied to the new destination when we write to the old destination. There are two subtleties:
\begin{enumerate}
\item \ocaml|if p then e1 else e2| has two subterms which are transformed in DPS style, and naively passing the stack of delayed constructors to both subterms would duplicate code; instead we also reify the current stack when encountering such constructs. For example,\\
\ocaml{  1 :: 2 :: if p then (3 :: f ()) else (4 :: f ())}%
becomes:\\
\ocaml{  let dst1 = 1 :: 2 :: ? in}\\
\ocaml{  if p then (let dst2 = 3 :: ? in dst1.1 <- dst2; f dst2 1 ())}\\
\ocaml{       else (let dst3 = 4 :: ? in dst1.1 <- dst3; f dst3 1 ())}

\item This transformation may permute constructor applications after effectful subterms. If the constructor application context frame contains possibly-effectful subterms (for example \ocaml{f x :: _? } instead of \ocaml{x :: _?}), the compiler must \ocaml|let|-bind them at their original position to avoid changing the evaluation order. For example,\\
\ocaml{x () :: (y (); f ())} does not become \ocaml{y (); (let dst = x () :: ? in ...)},
but instead \ocaml{let tmp = x () in (y (); let dst = tmp :: ? in ...)}.
\end{enumerate}

It is conceptually easy to extend our previous formalization of TMC as a rewriting relation to capture constructor compression, by indexing this relation on an additional list of constructor contexts. We do not present this here for lack of space, but included this change in our \Coq proofs, which establish correctness of TMC in presence of constructor compression.

\subsection{Implementation} \label{subsec:implementation} Implementing the TMC transform is not an obvious top-down or bottom-up traversal, because it relies on information flowing in two opposite directions: the transformation is \emph{possible} for subterms that are in tail-or-constructor position relative to the root of the function (top-down information), and it is \emph{desirable} for subterms whose leaves contain calls to TMC-transformed functions (bottom-up information). A naive approach is to perform a recursive traversal that tracks the top-down context and, on each subterm, recursively traverses the whole subterm to check desirability; this has quadratic time complexity, which is best avoided in production compilers.

Instead of trying to transform each subterm in a single pass, our implementation computes for each subterm a ``choice'', a summary of all the bottom-up information that is relevant to choose how to transform this subterm -- once we have the top-down information available. This includes (1) the direct-style transform of the subterm, (2) the DPS-style transform of the subterm, (3) metadata tracking whether the transformation is beneficial (if a TMC-function call was found in tail-modulo-cons position), the list of TMC calls it contains (for error diagnostics), and whether some were explicitly requested by the user (for disambiguation). Computing transformed terms is not compositional; computing choices is compositional. We compute a choice for the whole function body (in one pass), from which we can directly extract the direct-style and DPS-style transformations of the function.

\subsection{Evaluation: Benchmarks}

We measured the performance of \ocaml|List.map (fun n -> n + 1)| to validate our claims that the TMC transformation preserves program performance, and lets us replace complex hand-optimized tail-recursive implementations. \ocaml|List.map| is a worst-case: with most of the time spent in recursion and list construction, it is more sensitive to constant-factor overheads than other recursive functions.

\begin{figure}[tp]
\def\svgscale{0.8}
\graphicspath{{plots/}}
\input{plots/plot.5.pdf_tex}
\caption{\ocaml|List.map| benchmark on \OCaml~5.1}
\label{fig:bench5}
\end{figure}

\newcommand{\bench}[1]{\textbf{#1}}

The different versions we benchmark are the following. We measure the code size (in lines) of each version, as a reasonable approximation of its implementation complexity.
\begin{description}
\item[\bench{nontail}] (5 lines of code) The naive, non-tail-recursive implementation.
\item[\bench{tail}] (9 lines) The naive tail-recursive implementation,
  \ocaml{List.rev (List.rev_map f xs)}.
\item[\bench{base}] (78 lines) The implementation of Jane Street's
  \href{https://github.com/janestreet/base}{Base} library
  (version 0.14.0). It is heavily hand-optimized to compensate for the costs
  of being tail-recursive.
\item[\bench{containers}] (55 lines) Another standard-library extension by Simon
  Cruanes; it is the hand-optimized tail-recursive implementation we
  included in the Prologue.
\item[\bench{batteries}] (29 lines) The implementation of the community-maintained
  \href{https://github.com/ocaml-batteries-team/batteries-included/}{Batteries}
  library. It is actually written in destination-passing-style, using
  an unsafe encoding with \ocaml{Obj.magic} to unsafely cast a mutable
  record into a list cell. (The trick comes from the older Extlib
  library, was introduced by Brian Hurt in 2003, and has a comment crediting Jacques
  Garrigue for the particular encoding used.)
\item[\bench{tmc}] (5 lines) ``Our'' version, the last version of the Prologue: the
  result of applying our implementation of the TMC transformation to
  the simple, non-tail-recursive version.
\item[\bench{tmc-unrolled}] (18 lines) The result of manually unrolling the \bench{tmc} implementation three times, to be compared with \bench{base} and \bench{containers} that use manual unrolling as well.
\end{description}

The benchmarks reports the relative performance compared to the naive tail-recursive version as our baseline. They were run on \OCaml~5.1 in July 2024, on a Linux machine with an AMD Ryzen processor fixed at a 3Ghz frequency, looping each measurement for 5s (a single \ocaml|List.map| run takes between 7ns, for empty lists, and 89ms on lists with a million element).

Qualitatively we see that there are four groups:
\begin{itemize}
\item \bench{tmc}, \bench{batteries} perform very well on large lists, but they
  are slower than the baseline on small lists.
\item \bench{nontail} performs better than \bench{tmc}, \bench{batteries} on list sizes up to $10^4$, and much worse on larger lists.
\item \bench{base}, \bench{containers} perform noticeably better than \bench{nontail} at all sizes,
  but worse than the TMC versions above size $10^4$.
\item \bench{tmc-unrolled} is the best option: it performs as well as \bench{base} and \bench{containers} before $10^4$, and as well as \bench{tmc}, \bench{batteries} afterwards.
\end{itemize}
Our interpretation of the result is that some unrolling makes a noticeable performance difference for such a short function: \bench{tmc} is not good enough on smaller lists, but \bench{tmc-unrolled} is the best-performing, despite being much simpler than the \bench{base} and \bench{containers} versions.

\paragraph{Asymptotics of \bench{nontail}} The bad behavior of \bench{nontail} on large lists comes from a quadratic behavior on very large call stacks, coming from a repeated scan of the call stack during minor collections. (The \OCaml compiler and runtime could be tweaked to avoid this quadratic behavior, at the cost of some small constant overhead on function returns.)

% \paragraph{Memory usage} The \bench{tail} version allocates twice as many words as the \bench{tail} or TMC versions. The \bench{base} and \bench{containers} version allocate more as well, once they reach the cutoff where they move to their tail-recursive regime. This probably does not matter for most use-cases, and it does not show in the time measurements in the microbenchmark.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: