\section{\OCaml Implementation}
\label{sec:implementation}

\subsection{Alternative approaches}

Before we discuss our implementation of TMC in \OCaml, we mention other approaches than TMC to solve the problem of overflowing the call stack, and explain why they were unsuitable for \OCaml.

\subsubsection{Doing a CPS transformation}

Instead of a program transformation in \emph{destination-passing} style, we could perform a more general program transformation that can make more functions tail-recursive, for example a generic \emph{continuation-passing} style (CPS) transformation.

We have three arguments for implementing the TMC transformation:
\begin{itemize}
\item The TMC transformation generates more efficient code, using mutation instead of function calls. On the OCaml runtime, the difference is a large constant factor.\footnote{On a toy benchmark with large-sized lists, the CPS version is 100\% slower and has 130\% more allocations than the non-tail-recursive version.}

\item The CPS transformation can be expressed at the source level, and can be made reasonably nice-looking using some monadic-binding syntactic sugar. TMC can only be done by the compiler, or using safety-breaking features.
\end{itemize}

\subsection{Lazy data}

Lazy (call-by-need) languages will also often avoid running into stack overflows: as soon as a lazy datastructure is returned, which is the default, functions such as \ocaml{map} will return immediately, with recursive calls frozen in a lazy thunk, waiting to be evaluated on-demand as the user traverses the result structure.
User still need to worry about tail-recursivity for their strict functions; strict functions are often preferred when writing performant code.

\subsubsection{Unlimiting the system stack}

Some operating systems can provide an unlimited system stack; such as \texttt{ulimit -s unlimited} on Linux systems -- the system stack is then resized on-demand.
Frustratingly, unlimited stacks are not available on all systems, and not the default on any system in wide use.
Convincing all users to setup their system in a non-standard way would be \emph{much} harder than performing a program transformation or accepting the CPS overhead for some programs.

\subsubsection{Using another stack}

Using the native system stack is a choice of the OCaml 4 implementation.
Some other implementations of functional languages, such as SML/NJ, use a different stack (the OCaml bytecode interpreter does this), or directly allocate stack frames on their GC-managed heap.
This approach can make ``stack overflow'' go away completely, and it also makes it very simple to implement stack-capture control operators, such as continuations, or other stack operations such as continuation marks.

On the other hand, using the native stack brings compatibility benefits (coherent stack traces for mixed OCaml+C programs), and seems to improve the performance of function calls (on benchmarks that are only testing function calls and return, such as Ackermann or the naive Fibonacci, OCaml can be 4x, 5x faster than SML/NJ.)

\paragraph{OCaml 5}

OCaml 5.0.0 was released in December 2022, about a year after we landed our TMC implementation in the OCaml 4 compiler.
OCaml 5 uses a different runtime to support multicore programming, and a different calling convention to support algebraic effects.
In particular, it only uses the system stack for C calls, and a ``cactus stack'' for OCaml calls (stored outside the OCaml heap).

OCaml 5 manages its own stack, but the implementors still decided to have a stack limit.
It is sensibly higher by default (1Gio at the time of writing) than the system stack (8Mio), so many ``small'' can now use non-tail-recursive functions without fears of stack overflows, but overflows remain possible and likely in practice on large inputs.
The reason to keep a (user-settable) limit for the OCaml call stack is usability in the face of buggy programs.
When programmers write recursive functions, they occasionally go through incorrect versions with a faulty base case that fail to terminate.
In this case, we want the system to fail quickly with an error, instead of remaining silent for a few minutes, crashing once all the machine memory has been consumed.

We were curious about whether users would still see a need for TMC in OCaml 5, or whether they would stop using the feature in practice.
The feedback we got from expert users is that stack overflows is still an issue they worry about.
We observe that TMC adoption in OCaml codebases keep growing after the transition to OCaml 5.

\subsection{Implementation history}

We first proposed adding TMC as an optional program transformation to
the OCaml compiler in
May 2015.\footnote{\nonanon{URL}{\url{https://github.com/ocaml/ocaml/pull/181}}}
The proposal was received favorably, but it never received an in-depth
review and a detailed performance evaluation and remained unmerged for
years.

We re-activated the discussion in July 2020 with a modified
implementation, and a careful performance
evaluation\footnote{\nonanon{URL}{\url{https://github.com/ocaml/ocaml/pull/9760}}}. The
new implementation put a larger focus on producing readable code,
giving more control to the user through annotations. It also removed
an optimization of the previous implementation that would specialize
the DPS version, generating a distinct definition for each block
offset. The new design was carefully reviewed by Basile ClÃ©ment and
Pierre Chambart, and was finally merged in November 2021, available to
users with OCaml 4.14, released in March 2022.

The TMC transformation is that it adds extra parameters to functions
(two parameters, the block and the offset). At the time the OCaml
compiler had a limitation on some supported architectures, where it
would not optimze tail calls above a certain number of arguments
(enough that they cannot be all passed by registers), breaking the
tail-call promises of TMC on those systems. Xavier Leroy implemented
a change to the OCaml calling convention for those architectures in
May 2021,\footnote{\url{https://github.com/ocaml/ocaml/pull/10595}},
which was motivated by the TMC work.

\subsection{Examples}

Many functions that consume and produce lists are
tail-recursive-modulo-cons, in the sense that all they have a TMC
decomposition where all recursive calls are in TMC position. Notable
functions include \ocaml{map}, as already discussed, but also for
example:

\begin{Ocaml}
let[@tail_mod_cons] rec filter p = function
| [] -> []
| x :: xs -> if p x then x :: filter p xs else filter p xs

let[@tail_mod_cons] rec merge cmp l1 l2 =
  match l1, l2 with
  | [], l | l, [] -> l
  | h1 :: t1, h2 :: t2 ->
      if cmp h1 h2 <= 0
      then h1 :: merge cmp t1 l2
      else h2 :: merge cmp l1 t2
\end{Ocaml}

TMC is not useful only for lists or other ``linear'' data types, with
at most one recursive occurrence of the datatype in each
constructor.

\paragraph{A non-example} Consider a \ocaml{map} function on binary
trees:
\begin{Ocaml}
let[@tail_mod_cons] rec map f = function
| Leaf v -> Leaf (f v)
| Node(t1, t2) -> Node(map f t1, (map[@tailcall]) f t2)
\end{Ocaml}
In this function, there are two recursive calls, but only one of them
can be optimized; we used the \ocaml{[@tailcall]} attribute to direct
our implementation to optimize the call to the right child, as we will
discuss later. This is a \emph{bad} example of TMC usage in most
cases, given that
\begin{itemize}
\item If the tree is arbitrary, there is no reason that it would be
  right-leaning rather than left-leaning. Making only the right-child
  calls tail-calls does not protect us from stack overflows.
\item If the tree is known to be balanced, then in practice the depth
  is probably very small in both directions, so the TMC transformation
  is not necessary to have a well-behaved function.
\end{itemize}

\paragraph{Interesting non-linear examples} There \emph{are} interesting
examples of TMC-transformation on functions operating on tree-like
data structures, when there are natural assumptions about which child
is likely to contain a deep subtree. The OCaml compiler itself
contains a number of them; consider for example the following function
from the \ocaml{Cmm} module, one of its lower-level program
representations:
\begin{Ocaml}
let[@tail_mod_cons] rec map_tail f = function
  | Clet(id, exp, body) ->
      Clet(id, exp, map_tail f body)
  | Cifthenelse(cond, ifso, ifnot) ->
      Cifthenelse(cond, map_tail f ifso, (map_tail[@tailcall]) f ifnot)
  | Csequence(e1, e2) ->
      Csequence(e1, map_tail f e2)
  | Cswitch(e, tbl, el) ->
      Cswitch(e, tbl, Array.map (map_tail f) el)
  [...]
  | Cexit _ | Cop (Craise _, _, _) as cmm ->
      cmm
  | Cconst_int _ | Cvar _ | Ctuple _ | Cop _ as c ->
      f c
\end{Ocaml}

This function is traversing the ``tail'' context of an arbitrary
program term -- a meta-example! The \ocaml{Cifthenelse} node acts as
our binary-node constructor, we do not know which side is likely to be
larger, so TMC is not so interesting. The recursive calls for
\ocaml{Cswitch} are not in TMC position. But on the other hand the
\ocaml{Clet}, \ocaml{Csequence} cases are very beneficial to have in
TMC: while they have several recursive subtrees, they are in practice
only deeply nested in the direction that is turned into a tailcall by
the transformation. The OCaml compiler does sometimes encounter
machine-generated programs with a unusually long sequence of either
constructions, and the TMC transformation may very well avoid a stack
overflow in this case.

Another example would be
\href{https://github.com/ocaml/ocaml/pull/9636}{\#9636}, a patch to
the OCaml compiler proposed in June 2020 by Mark Shinwell, to get
a partially-tail-recursive implementation of the ``Common
Subexpression Elimination'' (CSE) pass through a manual
contiation-passing-style transform. Xavier Leroy remarked that the
existing implementation in fact fits the TMC fragment. Not all
recursive calls become tail-calls (this would require a more powerful
transformation or a longer, less readable patch), but the behavior of
TMC on the unchanged code matches the tail-call-ness proposed in the
human-written patch.

\subsection{Specifying which calls are in TMC position} \label{subsec:specification}
To reason about the stack usage of their programs, users must understand which calls are in tail-modulo-cons position.
Informally, they are the calls placed under any composition of either tail-recursive or constructor contexts.

We can in fact give a simple formal description of this intuition, here for \DataLang in \cref{fig:contexts}.
A tail frame $\datalangTailFrame$ is a single term-former with holes in tail-position.
A constructor frame $\datalangConsFrame$ is a single constructor term-former (we omit deterministic blocks, which do not occur in the source).
A tail context $\datalangTailCtx$ is an arbitrary composition of tail-frame, and a TMC context $\datalangTMCCtx$ is an arbitrary composition of tail frames and constructor frames.

If a source function can be decomposed in a TMC context $\datalangTMCCtx$ with source expressions in its holes, some of which are calls to TMC-transformed functions, then our relation admits a DPS transformation where all those function calls are tail-calls, and this transformation is reachable in our OCaml implementation, possibly by adding some annotations.

Note in particular that we do not optimize calls to the same function we are defining, direct calls to arbitrary other functions can be transformed, if those functions have been annotated to be TMC-transformed.
This is analoguous to how most functional languages support arbitrary \emph{tail calls} and not just tail self-recursion.
We seamlessly support mutually recursive functions, DPS calls into locally-bound functions, etc.

\begin{figure}[tp]
    \begin{tabular}{lclcl}
            $\datalangTailFrame[]$
            & $\ni$ &
            $\datalangTailFrame$
            & $\Coloneqq$ &
            $\datalangLet {\datalangVar} {\datalangExpr} \datalangCtxHole \mid \datalangIf \datalangExpr \datalangCtxHole \datalangCtxHole$
\\
            $\datalangConsFrame[]$
            & $\ni$ &
            $\datalangConsFrame$
            & $\Coloneqq$ &
            $\datalangBlock \datalangTag \datalangExpr \datalangCtxHole
            \mid \datalangBlock \datalangTag \datalangCtxHole \datalangExpr$
\\
            $\datalangTMCFrame[]$
            & $\ni$ &
            $\datalangTMCFrame$
            & $\Coloneqq$ &
            $\datalangTailFrame
             \mid
             \datalangConsFrame$
\\
            $\datalangTailCtx[]$
            & $\ni$ &
            $\datalangTailCtx$
            & $\Coloneqq$ &
            $\datalangCtxHole
             \mid
             \datalangTailFrame
             \mid
             \datalangTailCtx{[\datalangTailCtx]}$
\\
            $\datalangTMCCtx[]$
            & $\ni$ &
            $\datalangTMCCtx$
            & $\Coloneqq$ &
            $\datalangCtxHole
             \mid
             \datalangTMCFrame
             \mid
             \datalangTMCCtx{[\datalangTMCCtx]}$
    \end{tabular}
    \caption{\DataLang contexts for optimizable calls}
    \label{fig:contexts}
\end{figure}

\subsection{Design choices}

\subsubsection{Resolving non-determinism}

The main question faced by an implementation is how to resolve the
inherent non-determinism. We identified fairly different kinds of
non-determinism.

\paragraph{Choices with an obviously better alternative.} Some choices have an obviously better alternative, because they allow to strictly improve more programs. For example, some implementations of TMC limit themselves to calls that are immediately inside a constructor: they would optimize the recursive call to \ocaml|f| in \ocaml|Cons(x, f y)| but not, for example, in \ocaml|Cons(x1, Cons(x2, f y))|, or in \ocaml|Cons (x, if p then f y else z)|.

In the terms of \cref{subsec:specification}, some implementations only allow to optimize calling contexts of the form $\datalangTailCtx{[\datalangConsFrame]}$ or $\datalangTailCtx{[\datalangConsCtx]}$. We support a more general situation $\datalangTMCCtx = (\datalangTailFrame | \datalangConsFrame)^{*}$, at the cost of some implementation complexity.

\paragraph{Choices with a subtly better alternative.} In some cases it
is possible to put a bit more work in the choice heuristics, to
generate slightly better code, in terms of performance or
readability. For example, some natural way to simplify the
implementation would result in more subterms being transformed in
destination-passing-style, only to finally use the
\RefTirName{DPSBase} rule without any DPS function call. The generated
code is slightly less pleasant to read, and in our experience it can
be noticeably slower.

Code readability is important in our context of an on-demand program
transformation used by performance experts: those experts will often
read the intermediate representations produced by the compiler to
check that their performance assumptions hold.

\paragraph{Incomparable choices: force the user to decide} The
remaining choices are between incomparable alternatives, that could
each be better than the other depending on the specific program or
programmer intent. Consider again our binary tree example,
\ocaml|Node(map f left, map f right)|: we could make either the first
or the second argument a tail-call.

Our policy in such cases is to let the user decide, by providing
control over the transformation choices using \ocaml{[@tailcall]}
program annotations, and to force the user to decide by raising an
error in case of ambiguity:
\begin{Ocaml}
  | Cifthenelse(cond, ifso, ifnot) ->
      Cifthenelse(cond, map_tail f ifso, map_tail f ifnot)
      /[^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^]/
/[Error]/: "[@tail_mod_cons]": this constructor application may be TMC-transformed
       in several different ways. Please disambiguate by adding an explicit
       "[@tailcall]" attribute to the call that should be made tail-recursive,
       or a "[@tailcall false]" attribute on calls that should not be
       transformed.
\end{Ocaml}

This approach would be incompatible with a view of the TMC
transformation as an implicit optimization, applied whenever
possible -- in that case one would rather have the compiler make
arbitrary choices rather than fail. We rather view TMC as a tool for
expert users to better reason about program performance. It should be
predictable and flexible (let the user express
their intent). Failing on the lack of annotations is an acceptable way
to drive user interaction.

\subsubsection{First-order implementation} A notable limitation of the
OCaml implementation is that it is first-order and non-modular in
nature: only direct calls to known functions can be converted into DPS
style, and the availability of a DPS variant is not exposed through
module abstractions.

It would be possible to allow DPS calls through external modules or
higher-order function parameters, by annotating interfaces and
function arguments with a \ocaml{[@tail_mod_cons]} annotation, and
elaborating them into a pair of functions, the direct-style and the DPS
version.

\subsection{Constructor compression} \label{subsec:constructor-compression} The translation as we described it formally in \cref{subsec:transformation} generates unpleasant (and slower) code when many constructors are nested before the recursive call. For example, consider this strange function: element in a list:
\begin{Ocaml}
let rec dup = function [] -> [] | x :: xs -> x :: x :: dup xs
\end{Ocaml}
The DPS version, translated naively, would be as follows:
\begin{Ocaml}
let rec dup_dps dst ofs = function
| [] -> dst.(ofs) <- []
| x :: xs ->
  let dst1 = x :: ? in
  dst.(ofs) <- dst1;
  let dst2 = x :: ? in
  dst1.(1) <- dst2;
  dup_dps dst2 1 xs
\end{Ocaml}
Such nested constructors are common in compiler codebases, for
example a desugaring pass that transforms a single term-former into
a composition of several simpler term-formers, and applies recursively to
its subterms.

The TMC transformation implemented in OCaml performs ``constructor compression'', an optimization of the generated code that avoids creating intermediary destinations for nested constructors, generating instead the following code directly:
\begin{Ocaml}
let rec dup_dps dst ofs = function
| [] -> dst.(ofs) <- []
| x :: xs ->
  let dst2 = x :: ? in
  dst1.(1) <- x :: dst2;
  dup_dps dst2 1 xs
\end{Ocaml}

This is implemented by passing as an extra transformation parameter a stack of ``delayed'' constructor applications, that are in context and must be applied to the result of the subterm. When we encounter the final recursive call, we ``reify'' this stack: the last/innermost constructor in the stack becomes the new destination (\ocaml|dst1| in the example above), and the rest of the stack is applied to the new destination when we write to the old destination. There are two subtleties:
\begin{enumerate}
\item \ocaml|if p then e1 else e2| has two subterms which are transformed in DPS style, and naively passing the stack of delayed constructors to both subterms would duplicate code; instead of also reify the current stack when encountering such constructs.
\item This transformation may permute constructor applications after effectful subterms. If the constructor application contains effectful arguments, those must be \ocaml|let|-bound at their original position to avoid changing the evaluation order.
\end{enumerate}

\subsection{Implementation} \label{subsec:implementation} Implementing the TMC transform is not an obvious top-down or bottom-up traversal, because it relies on two informations flowing in opposite directions: the transformation is \emph{possible} for subterms that are in tail-or-constructor position relative to the root of the function (top-down information), and it is \emph{desirable} for subterms whose leaves contain calls to TMC-transformed functions (bottom-up information). A naive approach is to perform a recursive traversal that tracks the top-down context and, on each subterm, recursively traverses the whole subterm to check desirability; this has quadratic time complexity, which is best avoided in production compilers.

Instead of trying to transform each subterm in a single pass, our implementation computes for each subterm a ``choice'', a summary of all the bottom-up information relevant to choose how to transform it -- once we have the top-down information available. This includes (1) the direct-style transform of the subterm, (2) the DPS-style transform of the subterm, (3) metadata tracking whether the transformation is beneficial (if a TMC-function call was found in tail-modulo-cons position), the list of TMC calls it contains (for error diagnostics), and whether some were explicitly requested by the user (for disambiguation). Computing transformed terms is not compositional, computing choices is compositional. We compute a choice for the whole function body (in one pass), from which we can directly extract the direct-style and DPS-style transformations of the function.

The computation of choices can be expressed elegantly. Instead of a monomorphic type \ocaml|Choice.t| that represents a choice of how to transform a term, we use a polymorphic type \ocaml|'a Choice.t| that represents how to transform zero, one or several subterms that occur in the source; for example transforming two subterms in the same context relies on a choice of type \ocaml|(lambda * lambda) Choice.t|, where \ocaml|lambda| is the type of terms in the intermediate representation we are working on. This \ocaml|'a Choice.t| type can be equipped with an applicative functor interface:
\begin{Ocaml}
module Choice : sig
  type 'a t = {
    dps : 'a Dps.t;
    direct : unit -> 'a;
    tmc_calls : tmc_call_information list;
    benefits_from_dps : bool;
    explicit_tailcall_request : bool;
  }

  (* construct a choice from an arbitrary term *)
  val lambda : lambda -> lambda t

  (* applicative functor interface *)
  val unit : unit t
  val map : ('a -> 'b) -> 'a t -> 'b t
  val pair : 'a t * 'b t -> ('a * 'b) t

  (* extract the direct-style and DPS transforms *)
  val direct : lambda t -> lambda
  val dps : lamdba t -> tail:bool -> dst:offset destination -> 'd
end
\end{Ocaml}

With this interface, the easy cases of the transformation can be expressed compactly:
\begin{Ocaml}
  let rec choice ctx ~tail t =
    match t with
    (* base cases: no TMC call opportunities *)
    | (Lvar _ | Lmutvar _ | Lconst _ | Lfunction _ | Lsend _
      | Lassign _ | Lfor _ | Lwhile _) ->
        let t = traverse ctx t in
        Choice.lambda t

    (* congruence cases *)

    | Lifthenelse (l1, l2, l3) ->
        let l1 = traverse ctx l1 in
        let+ l2 = choice ctx ~tail l2
        and+ l3 = choice ctx ~tail l3
        in Lifthenelse (l1, l2, l3)

    | Lletrec (bindings, body) ->
        let ctx, bindings = traverse_letrec ctx bindings in
        let+ body = choice ctx ~tail body in
        Lletrec(bindings, body)

    (* .... *)

    (* hard cases: function and constructor application
       (omitted)  *)
\end{Ocaml}
The binding operators \ocaml|let+|, \ocaml|and+| are standard syntax for applicative-like structures in OCaml: \ocaml|let+| desugars to \ocaml|Choice.map| and \ocaml|and+| desugars to |Choice.pair|. \ocaml|traverse| performs a direct-style translation, and \ocaml|traverse_letrec| may also transform \ocaml|let|-bound functions marked with \ocaml|[@tail_mod_constr]| and add them to the local transformation environment.

\subsection{Evaluation: benchmarks}

We measured the performance of \ocaml|List.map| to validate our claims that the TMC transformation preserves program performance, and let us replace complex hand-optimized tail-recursive implementations.

\begin{figure}[tp]
\def\svgscale{0.8}
\graphicspath{{plots/}}
\input{plots/plot.4.pdf_tex}
\caption{\ocaml|List.map| benchmark on OCaml 4.14}
\label{fig:bench4}
\end{figure}

\begin{figure}[tp]
\def\svgscale{0.8}
\graphicspath{{plots/}}
\input{plots/plot.5.pdf_tex}
\caption{\ocaml|List.map| benchmark on OCaml 5.1}
\label{fig:bench5}
\end{figure}

TODO explain.

\subsection{Evaluation: adoption}

% [@tail_mod_cons] usage on Github

% Search URL:
%   https://github.com/search?q=tail_mod_cons+lang%3Aocaml&type=code

% Results (November 13th 2023):
%   - in the OCaml stdlib
%     + Melange
%       (reused from stdlib)
%     + janestreet/base
%       (with manual unfolding)
%   - in other general utility modules
%     https://github.com/RedPRL/asai/blob/ac523674579772e5929c8d912d407b8b7db89c74/src/Utils.ml#L33
%     https://github.com/jonathan-laurent/KaTie/blob/2db0d2cf223fae003b26bdf4c82a9788b5804bc7/src/utils.ml#L95
%     https://github.com/jamsidedown/ocaml-cll/blob/394effa65b5d3f883e2de8322ed60fb7aa495bec/examples/crab_cups.ml#L61
%   - in other user code
%     at list type:
%       https://github.com/brendanzab/language-garden/blob/9cc21e2f57228556cf0b867ca2874ceb4a4250ec/compile-arith/lib/StackLang.ml#L63
%       https://github.com/abella-prover/abella/blob/ceee13822001137898ca5de9c76a315da3d1f0e3/src/extensions.ml#L421
%       https://github.com/bikallem/spring/blob/6d10fef0b21caea3f975ff13132f5994e7c37db5/lib_spring/response.ml#L99
%       https://github.com/bikallem/spring/blob/6d10fef0b21caea3f975ff13132f5994e7c37db5/lib_spring/headers.ml#L150
%       https://github.com/polytypic/io/blob/dbe4d37a98ef958178fe18bb4dae396a5537392e/src/io/io.ml#L8
%       https://github.com/avsm/eeww/blob/5b6c0617306f4c9d8b44bf07ef4d45ec9668dd0c/lib/cohttp/cohttp-eio/src/rwer.ml#L43
%       https://github.com/just-max/less-power/blob/96f8e88f72275246b6bc175e44c732aa6e08ce7f/src/common/path_util.ml#L18
%       https://github.com/dalps/ocaml-challenge/blob/8fe115023457b6b4359ef736c78ba980cd871717/3/extract/solve.ml#L4
%       https://github.com/Octachron/ocaml-changelog-analyzer/blob/d6757b9576b5070ea3cfe6d4f4f79aaa3cc6e5d4/parse/release.ml#L4
%       https://github.com/Skyb0rg007/PL-Reading-Group/blob/7002ae35ba69fb9010e5049eee88ab475bc79ec3/list-optimizations/lib/adt.ml#L44
%       https://github.com/jfeser/symetric/blob/f49a57afc90a2c1e38f1097f98bd74725c074b9b/lib/tower.ml#L75
%       https://github.com/verse-lab/sisyphus/blob/a08addae06bbccb1e6ea68bac3d7f9eeea4197be/lib/dynamic/utils.ml#L65
%       https://github.com/jaymody/ocaml-tokenizers/blob/06cbce75d2865690cb39017222efff5c284bc721/lib/utils.ml#L18
%       https://github.com/Bannerets/ocaml-kdl/blob/687c404ebeceef7fd905935c23665294133f99e6/src/lens.ml#L83
%       https://github.com/OCADml/OCADml/blob/f5dfbf55f9c19ad808daa0df4d76a55e58756e5f/lib/poly3.ml#L33
%     other type
%       https://github.com/johnridesabike/acutis/blob/4113fb516d9c5dd6f2dbfd9657f52c5ae7a5dcae/lib/matching.ml#L161
%         (on-demand stream as a record of functions)
%       https://github.com/RedPRL/ocaml-bwd/blob/fbf496b29532085b38073eaa62ba3d22ac619d5d/src/BwdNoLabels.ml#L60
%         (snoc list)
%       https://github.com/Skyb0rg007/PL-Reading-Group/blob/7002ae35ba69fb9010e5049eee88ab475bc79ec3/effects/lib/free/tseq.ml#L44
%         (difference list gadt)

%   - Misuse
%     https://github.com/chengsun/simd-sexp/commit/e714a8205c6df512d920a31a4dd2448975703c55
%       (already tail-recursive)
%     https://github.com/gridbugs/llama/blob/96d1c96c31ff136f465b5f37c981fff591bac6fd/src/midi/byte_array_parser.ml#L50
%       (needless complexity)
%     https://github.com/LimitEpsilon/lambda-interpreter/blob/ab8e81de7f896aa64eba14e23d964b9705e94161/lib/evaluate.ml#L46
%       (already tail-recursive)

The TMC transformation was first made available to users in OCaml 4.14.0, released in March 2022.
At the time there were no users of the feature.
Notably, the OCaml standard library had intentionally not been modified to start using it: before the release, we did not want the stdlib codebase to depend on a not-available-yet feature, and after the release we decided not to push for adoption (we may be biased about the benefits/importance of TMC), and let other contributors propose its use, after doing their own evaluation of performance impact and code-clarity benefits.

Over time, \ocaml|[@tail_mod_cons]| was adopted in a few places in the OCaml standard library, either to make some functions tail-recursive that previously were not, or simplify some complex tail-recursive implementations. As of spring 2024, the feature is now used in \ocaml|Hashtbl.find_all| and in \ocaml|List| module (\ocaml|init, map, mapi, map2, find_all, filteri, filter_map, take, take_while, of_seq|). \ocaml|init| and the \ocaml|map*| functions, which are the most heavily used, were unrolled once -- the minimal amount observed to preserve the non-tailrec performance for small lists. Other functions are written in the simplest possible way. (All \texttt{stdlib} uses so far build lists rather than another datatype.)

We performed a systematic search for \ocaml|[@tail_mod_cons]| usage on November 2023, and we found that it was also used
\begin{itemize}
\item in a few utility modules (general-purpose functions designed to extend or replace the standard library), notably in Jane Street's \texttt{base} library.
\item in the middle of domain-specific user code, to build lists, in 14 different projects
\item in the middle of user code, to build other types than lists, in three projects:
  \begin{itemize}
  \item in \texttt{RedPRL}\footnote{\url{https://github.com/RedPRL/ocaml-bwd/blob/fbf496b29532085b38073eaa62ba3d22ac619d5d/src/BwdNoLabels.ml\#L60}},
    it is used to build snoc lists
  \item in a project named \texttt{PL-reading-group}\footnote{\url{https://github.com/Skyb0rg007/PL-Reading-Group/blob/7002ae35ba69fb9010e5049eee88ab475bc79ec3/effects/lib/free/tseq.ml\#L44}},
    it is used to build a GADT of difference lists
  \item in \texttt{acutis}\footnote{\url{https://github.com/johnridesabike/acutis/blob/4113fb516d9c5dd6f2dbfd9657f52c5ae7a5dcae/lib/matching.ml\#L161}},
    in a group of mutually-recursive functions that builds a complex AST structure used options and nested records
  \end{itemize}
\end{itemize}

We also found three cases where the annotation is (in our opinion) misused: in two cases, the function is already tail-recursive, so there is no need for the annotation, and in a third case\footnote{\url{https://github.com/gridbugs/llama/blob/96d1c96c31ff136f465b5f37c981fff591bac6fd/src/midi/byte_array_parser.ml\#L50}} we consider that the use is gratuitous and can be replaced by already-available standard library functions.
 

\subsection{TMC and OCaml 5}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End: